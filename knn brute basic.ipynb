{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=sqlite3.connect(\"/home/sushil/Downloads/databases/amazon-fine-food-reviews (1)/database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_sql_query(\"select * from reviews where Score!=3 limit 5000\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting data by product id \n",
    "sorted_data=data.sort_values(by=\"ProductId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x>3:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data.Score=sorted_data.Score.map(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4187\n",
       "0     813\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can say our data is an imbalance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=sorted_data.drop_duplicates(subset=[\"ProductId\",\"UserId\",\"Time\",\"Summary\",\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4997, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "#from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "from bs4 import BeautifulSoup\n",
    "#from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4997/4997 [00:02<00:00, 1895.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final_data['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4997"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "preprocessed_summary= []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final_data['Summary'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_summary.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4997"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one best choices opinion also adore amazon need negotiate better price tassimo disks available bedbath beyond always get brings readily available coupons months ago excellent blend full flavor not bitter think favorite',\n",
       " 'tried many tassimo flavors far favorite normal cup coffee starbuck house blend cuisinart pot one two days week use tassimo coffee rich not stong not understand current price disks hope lowered amazon buy elsewhere',\n",
       " 'bold blend great taste flavor comes bursting usually brew drink organic sumatra mandeling bj use blend exclusively get cup rivals complex flavor tassimo brewer fantastic come amazon add subscription service',\n",
       " 'coffee available tassimo kona richest flavor fantastic aroma byfar favorite']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_reviews[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushil/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "final_data.Text=preprocessed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data.Summary=preprocessed_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great coffee terrible price',\n",
       " 'best tassimo',\n",
       " 'good tasting cup joe',\n",
       " 'kona tassimo',\n",
       " 'weak coffee not good premium product price']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_summary[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2546                                  thirty bucks\n",
       "2547                                  flies begone\n",
       "1145                            wow make islickers\n",
       "1146                                 great product\n",
       "2942                                    good stuff\n",
       "                           ...                    \n",
       "711                    great coffee terrible price\n",
       "710                                   best tassimo\n",
       "709                           good tasting cup joe\n",
       "713                                   kona tassimo\n",
       "1362    weak coffee not good premium product price\n",
       "Name: Summary, Length: 4997, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2546    product available victor traps unreal course t...\n",
       "2547    used victor fly bait seasons ca not beat great...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.Text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=final_data.drop(columns=[\"HelpfulnessNumerator\",\"HelpfulnessDenominator\"])\n",
    "#the code has been ruuned and saved hence showing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time=final_data.sort_values(by=\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1245</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A29Z5PI9BW2PU3</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>1</td>\n",
       "      <td>961718400</td>\n",
       "      <td>great product</td>\n",
       "      <td>really good idea final product outstanding use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1244</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A3B8RCEI0FXFI6</td>\n",
       "      <td>B G Chase</td>\n",
       "      <td>1</td>\n",
       "      <td>962236800</td>\n",
       "      <td>wow make islickers</td>\n",
       "      <td>received shipment could hardly wait try produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>3783</td>\n",
       "      <td>B00016UX0K</td>\n",
       "      <td>AF1PV3DIC0XM7</td>\n",
       "      <td>Robert Ashton</td>\n",
       "      <td>1</td>\n",
       "      <td>1081555200</td>\n",
       "      <td>classic condiment</td>\n",
       "      <td>mae ploy sweet chili sauce becoming standard c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1206</td>\n",
       "      <td>B005O072PC</td>\n",
       "      <td>A3BD5B8Y8MY25X</td>\n",
       "      <td>J. L. K. \"special_k\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1088467200</td>\n",
       "      <td>best twice baked potatoes ever</td>\n",
       "      <td>perfect year round meat dish omaha steaks twic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1276</td>\n",
       "      <td>B000WNJ73Q</td>\n",
       "      <td>A394MHK3CSDGUV</td>\n",
       "      <td>kaleinor</td>\n",
       "      <td>1</td>\n",
       "      <td>1091318400</td>\n",
       "      <td>woofs</td>\n",
       "      <td>five five dogs agree would rather munch liver ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId           ProfileName  Score  \\\n",
       "1146  1245  B00002Z754  A29Z5PI9BW2PU3                Robbie      1   \n",
       "1145  1244  B00002Z754  A3B8RCEI0FXFI6             B G Chase      1   \n",
       "3481  3783  B00016UX0K   AF1PV3DIC0XM7         Robert Ashton      1   \n",
       "1112  1206  B005O072PC  A3BD5B8Y8MY25X  J. L. K. \"special_k\"      1   \n",
       "1176  1276  B000WNJ73Q  A394MHK3CSDGUV              kaleinor      1   \n",
       "\n",
       "            Time                         Summary  \\\n",
       "1146   961718400                   great product   \n",
       "1145   962236800              wow make islickers   \n",
       "3481  1081555200               classic condiment   \n",
       "1112  1088467200  best twice baked potatoes ever   \n",
       "1176  1091318400                           woofs   \n",
       "\n",
       "                                                   Text  \n",
       "1146  really good idea final product outstanding use...  \n",
       "1145  received shipment could hardly wait try produc...  \n",
       "3481  mae ploy sweet chili sauce becoming standard c...  \n",
       "1112  perfect year round meat dish omaha steaks twic...  \n",
       "1176  five five dogs agree would rather munch liver ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec=CountVectorizer(min_df=10)\n",
    "count_vec.fit(final_time.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'able', 'absolute', 'absolutely', 'according', 'acid', 'acidic', 'acidity', 'across', 'active', 'actual', 'actually', 'add', 'added', 'addict', 'addicted', 'addicting', 'addictive', 'adding', 'addition', 'additional', 'additionally', 'additives', 'adds', 'admit', 'adopted', 'adore', 'adult', 'adults', 'advertised', 'afford', 'affordable', 'afraid', 'afternoon', 'aftertaste', 'afterwards', 'agave', 'age', 'ages', 'ago', 'agree', 'ahead', 'ahoy', 'aid', 'air', 'alcohol', 'allergic', 'allergies', 'allergy', 'allow', 'allowed', 'allows', 'almond', 'almonds', 'almost', 'alone', 'along', 'alot', 'already', 'also', 'alternative', 'alternatives', 'although', 'always', 'amazed', 'amazing', 'amazon', 'american', 'among', 'amount', 'amounts', 'animal', 'animals', 'another', 'anti', 'antioxidants', 'anymore', 'anyone', 'anything', 'anytime', 'anyway', 'anywhere', 'apart', 'apparently', 'appealing', 'appears', 'apple', 'apples', 'appreciate', 'area', 'argentina', 'aroma', 'around', 'arrive', 'arrived', 'artificial', 'asian', 'aside', 'ask', 'asked', 'assortment', 'ate', 'attention', 'audio', 'authentic', 'auto', 'available', 'average', 'avoid', 'aware', 'away', 'awesome', 'awful', 'awhile', 'babies', 'baby', 'back', 'bacon', 'bad', 'bag', 'bags', 'bake', 'baked', 'baker', 'baking', 'balance', 'balanced', 'ball', 'balls', 'banana', 'bananas', 'bar', 'barbecue', 'barbeque', 'barely', 'bargain', 'bars', 'base', 'based', 'basic', 'basically', 'basil', 'basis', 'basket', 'batch', 'batches', 'batter', 'bbq', 'bean', 'beans', 'beat', 'beats', 'beautiful', 'became', 'become', 'bed', 'beef', 'beer', 'began', 'begin', 'beginning', 'behind', 'belgian', 'believe', 'belly', 'benefit', 'benefits', 'berry', 'besides', 'best', 'better', 'betty', 'beverage', 'beverages', 'beware', 'beyond', 'big', 'bigger', 'bill', 'birthday', 'biscotti', 'biscuit', 'biscuits', 'bisquick', 'bit', 'bite', 'bites', 'bits', 'bitter', 'bitterness', 'black', 'bland', 'blend', 'blends', 'blood', 'blue', 'blueberries', 'blueberry', 'bob', 'bodied', 'body', 'bold', 'bonus', 'book', 'boost', 'boot', 'boring', 'bother', 'bottle', 'bottled', 'bottles', 'bottom', 'bought', 'bowl', 'box', 'boxes', 'boy', 'boyfriend', 'boys', 'brand', 'brands', 'bread', 'breads', 'break', 'breakfast', 'breaking', 'breath', 'breed', 'brew', 'brewed', 'brewer', 'brewing', 'brews', 'bright', 'bring', 'brings', 'broke', 'broken', 'brother', 'brought', 'brown', 'brownie', 'brownies', 'bubble', 'bucks', 'buds', 'buffalo', 'bulk', 'bunch', 'burn', 'burned', 'burnt', 'business', 'busy', 'butter', 'buttermilk', 'buy', 'buyer', 'buying', 'ca', 'cable', 'cacao', 'cafe', 'caffeine', 'cajun', 'cake', 'cakes', 'cal', 'calcium', 'california', 'call', 'called', 'calls', 'calorie', 'calories', 'came', 'candies', 'candy', 'cane', 'canned', 'cannot', 'canola', 'cans', 'cant', 'car', 'caramel', 'carb', 'carbs', 'cardboard', 'care', 'careful', 'carefully', 'caribou', 'carried', 'carries', 'carrot', 'carrots', 'carry', 'carrying', 'case', 'cases', 'cat', 'cats', 'cause', 'caused', 'celiac', 'center', 'cents', 'cereal', 'certain', 'certainly', 'certified', 'chance', 'change', 'changed', 'changing', 'charge', 'charges', 'cheap', 'cheaper', 'cheapest', 'check', 'checked', 'cheddar', 'cheese', 'chemical', 'chemicals', 'cherry', 'chew', 'chewing', 'chewy', 'chicken', 'child', 'childhood', 'children', 'chili', 'china', 'chinese', 'chip', 'chips', 'chocolate', 'chocolates', 'chocolatey', 'chocolaty', 'choice', 'choices', 'choke', 'cholesterol', 'choose', 'chopped', 'chose', 'chowder', 'christmas', 'chunks', 'cilantro', 'cinnamon', 'city', 'claim', 'claims', 'clam', 'clams', 'class', 'classic', 'clean', 'clear', 'clearly', 'close', 'closed', 'closer', 'closest', 'co', 'coat', 'coated', 'coating', 'coats', 'cocker', 'coco', 'cocoa', 'coconut', 'coffee', 'coffees', 'cold', 'collection', 'color', 'colored', 'colors', 'com', 'combination', 'combined', 'combo', 'come', 'comes', 'coming', 'comment', 'commented', 'comments', 'commercial', 'common', 'community', 'companies', 'company', 'comparable', 'compare', 'compared', 'comparison', 'complain', 'complained', 'complaint', 'complaints', 'complete', 'completely', 'computer', 'concentrate', 'concerned', 'concerns', 'condenser', 'condition', 'cons', 'consider', 'considered', 'considering', 'consistency', 'consistent', 'consistently', 'constantly', 'consume', 'consumed', 'consumer', 'consuming', 'consumption', 'contact', 'contacted', 'contain', 'contained', 'container', 'containers', 'containing', 'contains', 'content', 'contents', 'continue', 'control', 'convenience', 'convenient', 'cook', 'cooked', 'cookie', 'cookies', 'cooking', 'cooks', 'cool', 'corn', 'corner', 'cost', 'costco', 'costs', 'could', 'count', 'counter', 'country', 'couple', 'coupon', 'course', 'cover', 'covered', 'cracked', 'cracker', 'crackers', 'crap', 'craving', 'cravings', 'crazy', 'cream', 'creamer', 'creamy', 'create', 'crisp', 'crisps', 'crispy', 'crocker', 'crumble', 'crumbly', 'crumbs', 'crunch', 'crunchy', 'crust', 'cup', 'cups', 'current', 'currently', 'customer', 'customers', 'cut', 'cute', 'cutting', 'dad', 'daily', 'dairy', 'damage', 'damaged', 'dark', 'date', 'dates', 'daughter', 'day', 'days', 'de', 'dead', 'deal', 'death', 'decaf', 'decaffeinated', 'decent', 'decide', 'decided', 'deep', 'definately', 'definitely', 'delicate', 'delicious', 'delight', 'delighted', 'delightful', 'delivered', 'delivery', 'dense', 'dented', 'depending', 'describe', 'described', 'description', 'design', 'designed', 'desk', 'despite', 'dessert', 'device', 'diabetic', 'diagnosed', 'diarrhea', 'didnt', 'die', 'diet', 'difference', 'different', 'difficult', 'digest', 'digestive', 'dijon', 'dinner', 'dinners', 'dip', 'dipping', 'directions', 'directly', 'dirty', 'disappointed', 'disappointing', 'disappointment', 'discontinued', 'discount', 'discover', 'discovered', 'disease', 'disgusting', 'dish', 'dishes', 'dislike', 'dissapointed', 'dissolve', 'dissolves', 'distinct', 'doctor', 'dog', 'dogs', 'dollar', 'dollars', 'done', 'dont', 'door', 'double', 'doubt', 'dough', 'downside', 'dr', 'drank', 'drawback', 'dressing', 'dressings', 'dried', 'drink', 'drinker', 'drinkers', 'drinking', 'drinks', 'drip', 'drive', 'drop', 'drops', 'dry', 'due', 'dumplings', 'dust', 'earlier', 'early', 'earth', 'ease', 'easier', 'easily', 'easy', 'eat', 'eaten', 'eater', 'eaters', 'eating', 'eats', 'economical', 'edible', 'effect', 'effective', 'effects', 'effort', 'egg', 'eggs', 'either', 'electrolytes', 'else', 'elsewhere', 'em', 'email', 'empty', 'end', 'ended', 'energy', 'england', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enjoying', 'enjoys', 'enough', 'entire', 'entirely', 'equal', 'equally', 'escapes', 'especially', 'espresso', 'etc', 'europe', 'european', 'even', 'evening', 'eventually', 'ever', 'every', 'everyday', 'everyone', 'everything', 'everywhere', 'exact', 'exactly', 'example', 'excellent', 'except', 'excited', 'exotic', 'expect', 'expectations', 'expected', 'expecting', 'expensive', 'experience', 'experienced', 'expiration', 'expired', 'extra', 'extract', 'extremely', 'eye', 'eyes', 'fabulous', 'face', 'fact', 'fair', 'fairly', 'fake', 'fall', 'family', 'fan', 'fancy', 'fans', 'fantastic', 'far', 'farms', 'fast', 'faster', 'fat', 'father', 'fats', 'fattening', 'favor', 'favorite', 'favorites', 'favors', 'fed', 'feed', 'feeding', 'feel', 'feeling', 'feels', 'felidae', 'fell', 'felt', 'fewer', 'fiber', 'figure', 'figured', 'fill', 'filled', 'fillers', 'filling', 'finally', 'find', 'finding', 'fine', 'finger', 'fingers', 'finish', 'finished', 'firm', 'first', 'fish', 'fit', 'fits', 'five', 'fix', 'flat', 'flavor', 'flavored', 'flavorful', 'flavoring', 'flavorings', 'flavors', 'flavour', 'flax', 'floor', 'flour', 'fluffy', 'folks', 'follow', 'followed', 'following', 'food', 'foods', 'forever', 'forget', 'form', 'formula', 'forward', 'found', 'four', 'fragile', 'free', 'freeze', 'freezer', 'french', 'frequently', 'fresh', 'fresher', 'freshness', 'fridge', 'fried', 'friend', 'friendly', 'friends', 'front', 'frosting', 'frozen', 'fructose', 'fruit', 'fruits', 'fruity', 'full', 'fully', 'fun', 'funny', 'fur', 'future', 'gain', 'gallon', 'game', 'garbage', 'garlic', 'gas', 'gatorade', 'gave', 'general', 'generally', 'german', 'get', 'gets', 'getting', 'gevalia', 'gf', 'gift', 'gifts', 'ginger', 'gingerbread', 'girl', 'girlfriend', 'give', 'given', 'gives', 'giving', 'glad', 'glass', 'gluten', 'go', 'goes', 'going', 'gold', 'golden', 'gone', 'good', 'goodness', 'goods', 'google', 'got', 'gotten', 'gourmet', 'grab', 'graham', 'grain', 'grains', 'grainy', 'grams', 'grandson', 'granted', 'grape', 'grass', 'gravy', 'grease', 'greasy', 'great', 'greatest', 'green', 'grew', 'grey', 'grind', 'grinder', 'grinding', 'gritty', 'grocery', 'gross', 'ground', 'group', 'grove', 'grow', 'growing', 'grown', 'guess', 'guests', 'guilt', 'guilty', 'gum', 'guy', 'guys', 'habit', 'hair', 'half', 'hand', 'handful', 'handle', 'hands', 'handy', 'happen', 'happened', 'happens', 'happier', 'happily', 'happy', 'hard', 'harder', 'hardly', 'harmony', 'hate', 'hated', 'hazelnut', 'head', 'health', 'healthier', 'healthy', 'heard', 'heart', 'hearty', 'heat', 'heated', 'heaven', 'heavier', 'heavily', 'heavy', 'help', 'helped', 'helpful', 'helping', 'helps', 'herb', 'herbal', 'herbs', 'hershey', 'hey', 'high', 'higher', 'highly', 'hint', 'hit', 'hits', 'hodgson', 'hold', 'holds', 'holes', 'holiday', 'home', 'homemade', 'honest', 'honestly', 'honey', 'hooked', 'hope', 'hopefully', 'hoping', 'horrible', 'horses', 'hot', 'hour', 'hours', 'house', 'household', 'however', 'hubby', 'huge', 'hulls', 'human', 'hungry', 'husband', 'hydrogenated', 'iams', 'ice', 'iced', 'icicle', 'icing', 'idea', 'ideal', 'im', 'imagine', 'immediately', 'important', 'importantly', 'impossible', 'impressed', 'improved', 'improvement', 'inches', 'include', 'included', 'includes', 'including', 'increase', 'incredible', 'incredibly', 'individual', 'individually', 'inexpensive', 'info', 'information', 'ingredient', 'ingredients', 'initial', 'inside', 'instant', 'instantly', 'instead', 'instructions', 'intact', 'intake', 'intense', 'interested', 'interesting', 'internet', 'intolerant', 'introduced', 'iron', 'issue', 'issues', 'italian', 'italy', 'item', 'items', 'jack', 'jalapeno', 'jam', 'japan', 'japanese', 'jar', 'jars', 'jelly', 'jerky', 'job', 'joe', 'juice', 'juices', 'junk', 'kavli', 'kcup', 'keep', 'keeping', 'keeps', 'kept', 'kernels', 'ketchup', 'kettle', 'keurig', 'key', 'kibble', 'kick', 'kid', 'kidding', 'kids', 'kind', 'kinda', 'kinds', 'kit', 'kitchen', 'knew', 'knob', 'know', 'knowing', 'known', 'knows', 'kona', 'kosher', 'lab', 'label', 'labels', 'lack', 'lacking', 'lacks', 'ladies', 'lamb', 'large', 'larger', 'last', 'lasted', 'lasting', 'lasts', 'late', 'lately', 'later', 'law', 'lay', 'lays', 'lb', 'lbs', 'leaf', 'learn', 'learned', 'least', 'leave', 'leaves', 'left', 'lemon', 'lemonade', 'length', 'less', 'let', 'level', 'levels', 'licorice', 'lid', 'life', 'light', 'lighter', 'lightly', 'like', 'liked', 'likely', 'likes', 'liking', 'lime', 'limit', 'limited', 'line', 'liquid', 'list', 'listed', 'literally', 'little', 'live', 'lived', 'liver', 'lives', 'living', 'loaded', 'loaf', 'lobster', 'local', 'locally', 'lock', 'lol', 'lollipops', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'loose', 'lose', 'loss', 'lost', 'lot', 'lots', 'love', 'loved', 'lovely', 'lover', 'lovers', 'loves', 'loving', 'low', 'lower', 'lowest', 'luck', 'lunch', 'lunches', 'machine', 'made', 'mahogany', 'mail', 'main', 'maintain', 'major', 'make', 'maker', 'makes', 'making', 'maltodextrin', 'man', 'mango', 'manner', 'manufactured', 'manufacturer', 'manufacturers', 'many', 'maple', 'marinade', 'mark', 'market', 'markets', 'marzano', 'mass', 'match', 'matter', 'may', 'maybe', 'meal', 'meals', 'mean', 'means', 'meant', 'measure', 'meat', 'meats', 'medium', 'meet', 'melitta', 'mellow', 'melt', 'melted', 'members', 'mention', 'mentioned', 'mess', 'messy', 'met', 'metal', 'mg', 'mic', 'microphone', 'microwave', 'mics', 'mid', 'middle', 'might', 'mild', 'miles', 'milk', 'mill', 'mind', 'mine', 'minerals', 'mini', 'mint', 'minute', 'minutes', 'misleading', 'miss', 'missed', 'missing', 'mistake', 'mix', 'mixed', 'mixes', 'mixing', 'mixture', 'modified', 'moist', 'molasses', 'mom', 'money', 'month', 'monthly', 'months', 'morning', 'mornings', 'mostly', 'mother', 'mountain', 'mouth', 'move', 'moved', 'movie', 'moving', 'mrs', 'msg', 'much', 'muffin', 'muffins', 'mug', 'multiple', 'mushy', 'must', 'mustard', 'name', 'nasty', 'natural', 'naturally', 'nature', 'near', 'nearby', 'nearly', 'nectar', 'need', 'needed', 'needless', 'needs', 'negative', 'neither', 'never', 'new', 'newman', 'newmans', 'next', 'nice', 'nicely', 'night', 'no', 'noise', 'non', 'none', 'noodles', 'nor', 'normal', 'normally', 'nose', 'not', 'note', 'noted', 'nothing', 'notice', 'noticed', 'number', 'numerous', 'nut', 'nutrients', 'nutrition', 'nutritional', 'nutritious', 'nuts', 'oatmeal', 'oats', 'obviously', 'occasion', 'occasional', 'occasionally', 'odd', 'offer', 'offered', 'offering', 'offers', 'office', 'often', 'oh', 'oil', 'oils', 'oily', 'ok', 'okay', 'old', 'older', 'oldest', 'olive', 'olives', 'omaha', 'omega', 'one', 'ones', 'onion', 'online', 'onto', 'oolong', 'open', 'opened', 'opening', 'opinion', 'opportunity', 'opposed', 'option', 'options', 'orange', 'order', 'ordered', 'ordering', 'oreo', 'oreos', 'organic', 'organics', 'original', 'originally', 'others', 'otherwise', 'ounce', 'ounces', 'outside', 'outstanding', 'oven', 'overall', 'overly', 'overpowering', 'overwhelming', 'owner', 'oz', 'pack', 'package', 'packaged', 'packages', 'packaging', 'packed', 'packet', 'packets', 'packing', 'packs', 'page', 'paid', 'pain', 'palatable', 'pamela', 'pan', 'pancake', 'pancakes', 'panda', 'pantry', 'paper', 'part', 'partially', 'particular', 'particularly', 'parties', 'parts', 'party', 'pass', 'past', 'pasta', 'paste', 'pay', 'paying', 'peach', 'peanut', 'peanuts', 'pear', 'peas', 'penny', 'people', 'pepper', 'peppermint', 'per', 'perfect', 'perfectly', 'perhaps', 'period', 'person', 'personal', 'personally', 'pet', 'pets', 'phantom', 'photo', 'pick', 'picked', 'picky', 'picture', 'pictures', 'pie', 'piece', 'pieces', 'pineapple', 'pizza', 'place', 'placed', 'plain', 'plan', 'plant', 'plants', 'plastic', 'play', 'pleasant', 'pleasantly', 'please', 'pleased', 'pleasing', 'pleasure', 'plenty', 'plug', 'plus', 'pocket', 'pod', 'pods', 'point', 'points', 'pomegranate', 'poor', 'pop', 'popchips', 'popcorn', 'popped', 'popper', 'popping', 'pops', 'popular', 'pork', 'portable', 'portion', 'portions', 'positive', 'possible', 'post', 'pot', 'potassium', 'potato', 'potatoes', 'pouch', 'pouches', 'pound', 'pounds', 'pour', 'poured', 'powder', 'powdered', 'power', 'powering', 'pre', 'prefer', 'preference', 'premium', 'prepare', 'prepared', 'present', 'preservatives', 'press', 'pressure', 'pretty', 'prevent', 'previous', 'previously', 'price', 'priced', 'prices', 'pricey', 'prime', 'pro', 'probably', 'problem', 'problems', 'process', 'processed', 'produce', 'produced', 'product', 'products', 'program', 'prompt', 'promptly', 'properly', 'pros', 'protein', 'provide', 'provided', 'provides', 'pudding', 'pull', 'punch', 'puppy', 'purchase', 'purchased', 'purchases', 'purchasing', 'pure', 'purina', 'purpose', 'purse', 'put', 'putting', 'quality', 'quantity', 'question', 'quick', 'quickly', 'quite', 'raise', 'ramen', 'ran', 'rancid', 'range', 'rare', 'rarely', 'raspberry', 'rate', 'rated', 'rather', 'rating', 'ratio', 'rave', 'raw', 'reach', 'reaction', 'read', 'readily', 'reading', 'ready', 'real', 'realize', 'realized', 'really', 'reason', 'reasonable', 'reasonably', 'receive', 'received', 'receiving', 'recent', 'recently', 'recipe', 'recipes', 'recommend', 'recommendation', 'recommended', 'record', 'recording', 'red', 'reduced', 'reflux', 'refreshing', 'refrigerator', 'refund', 'refused', 'regarding', 'regret', 'regular', 'regularly', 'relatively', 'reliable', 'remember', 'remind', 'reminded', 'reminds', 'remove', 'reorder', 'replace', 'replaced', 'replacement', 'require', 'required', 'requires', 'resealable', 'research', 'response', 'rest', 'restaurant', 'restaurants', 'result', 'results', 'retail', 'return', 'returned', 'review', 'reviewer', 'reviewers', 'reviews', 'rice', 'rich', 'rid', 'ridiculous', 'right', 'rip', 'risk', 'riviera', 'road', 'roast', 'roasted', 'robust', 'rock', 'roll', 'rolls', 'room', 'root', 'rose', 'rough', 'round', 'ruin', 'run', 'running', 'runny', 'runs', 'sad', 'safe', 'said', 'salad', 'salads', 'sale', 'sales', 'salmon', 'salsa', 'salt', 'salted', 'salty', 'sample', 'sampler', 'san', 'sandwich', 'sandwiches', 'sardines', 'satisfied', 'satisfy', 'satisfying', 'sauce', 'sauces', 'sausage', 'save', 'saved', 'saves', 'saving', 'savor', 'savory', 'saw', 'say', 'saying', 'says', 'scent', 'schedule', 'school', 'science', 'scissors', 'scratch', 'sea', 'seal', 'sealed', 'search', 'searched', 'searching', 'season', 'seasoned', 'seasoning', 'seasonings', 'second', 'seconds', 'see', 'seed', 'seeds', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'select', 'selection', 'sell', 'seller', 'selling', 'sells', 'send', 'sending', 'senior', 'sense', 'sensitive', 'sent', 'separate', 'serious', 'seriously', 'serve', 'served', 'service', 'serving', 'servings', 'sesame', 'set', 'setting', 'several', 'severe', 'shake', 'shame', 'shape', 'shaped', 'share', 'shared', 'shelf', 'shell', 'shelves', 'shiny', 'ship', 'shipment', 'shipments', 'shipped', 'shipping', 'shocked', 'shop', 'shopping', 'short', 'shot', 'shots', 'show', 'shower', 'shown', 'shows', 'shrimp', 'sick', 'side', 'sign', 'silky', 'similar', 'simple', 'simply', 'since', 'single', 'sinus', 'sip', 'sister', 'sit', 'site', 'sites', 'sitting', 'situation', 'six', 'size', 'sized', 'sizes', 'skeptical', 'skin', 'skip', 'sleep', 'slice', 'sliced', 'slices', 'slight', 'slightly', 'slow', 'slowly', 'small', 'smaller', 'smallest', 'smell', 'smelled', 'smells', 'smooth', 'smoother', 'smoothies', 'snack', 'snacking', 'snacks', 'snap', 'snob', 'snow', 'soaked', 'soda', 'sodium', 'soft', 'softer', 'software', 'sold', 'solid', 'solution', 'somehow', 'someone', 'something', 'sometimes', 'somewhat', 'somewhere', 'son', 'soon', 'sooo', 'sorry', 'sort', 'sound', 'sounds', 'soup', 'soups', 'sour', 'source', 'south', 'soy', 'soybean', 'special', 'specific', 'specifically', 'spend', 'spent', 'spice', 'spices', 'spicy', 'spilled', 'splash', 'splenda', 'split', 'spoiled', 'spoon', 'sports', 'spot', 'spread', 'spring', 'sprinkle', 'square', 'squeeze', 'stage', 'stale', 'stand', 'standard', 'stands', 'staple', 'star', 'starbucks', 'starch', 'stars', 'start', 'started', 'starting', 'starts', 'stash', 'state', 'stated', 'states', 'station', 'stay', 'stays', 'steaks', 'steal', 'steep', 'step', 'stevia', 'stick', 'sticks', 'sticky', 'still', 'stir', 'stock', 'stocking', 'stomach', 'stonewall', 'stools', 'stop', 'stopped', 'storage', 'store', 'stores', 'story', 'stove', 'straight', 'strange', 'strawberries', 'strawberry', 'strength', 'strong', 'stronger', 'stuck', 'stuff', 'stumbled', 'sturdy', 'style', 'subscribe', 'subscription', 'substitute', 'subtle', 'success', 'sucralose', 'sugar', 'sugars', 'sugary', 'suggest', 'suggested', 'summer', 'sunflower', 'sunset', 'super', 'superb', 'superior', 'supermarket', 'supermarkets', 'supplement', 'supplier', 'supply', 'support', 'supposed', 'sure', 'surprise', 'surprised', 'surprisingly', 'sweet', 'sweetened', 'sweetener', 'sweeteners', 'sweeter', 'sweetner', 'sweetness', 'sweets', 'swiss', 'switch', 'switched', 'switching', 'syrup', 'system', 'table', 'tablespoon', 'tablespoons', 'take', 'taken', 'takes', 'taking', 'talk', 'talking', 'tangy', 'target', 'tart', 'tassimo', 'taste', 'tasted', 'tasteless', 'tastes', 'tastier', 'tasting', 'tasty', 'tea', 'teas', 'teaspoon', 'teeth', 'tell', 'temperature', 'ten', 'tend', 'tender', 'term', 'terms', 'terrible', 'terrier', 'terrific', 'test', 'texture', 'thai', 'thank', 'thankful', 'thanks', 'thats', 'themed', 'therefore', 'thick', 'thicken', 'thicker', 'thin', 'thing', 'things', 'think', 'thinking', 'thinks', 'thinner', 'third', 'thoroughly', 'though', 'thought', 'three', 'threw', 'thrilled', 'throughout', 'throw', 'throwing', 'thrown', 'thus', 'tic', 'tight', 'time', 'timely', 'times', 'tin', 'tiny', 'tips', 'tired', 'toast', 'today', 'toddler', 'together', 'told', 'tolerate', 'tomato', 'tomatoes', 'ton', 'tongue', 'tons', 'took', 'tooth', 'top', 'topping', 'tortilla', 'toss', 'tossed', 'total', 'totally', 'touch', 'tough', 'town', 'traditional', 'training', 'trans', 'trash', 'travel', 'traveling', 'treat', 'treats', 'tree', 'trick', 'tried', 'trip', 'trips', 'trouble', 'true', 'truly', 'trust', 'try', 'trying', 'tsp', 'tube', 'tummy', 'tuna', 'turkey', 'turn', 'turned', 'turns', 'twice', 'two', 'type', 'types', 'typical', 'typically', 'unable', 'uncle', 'understand', 'unfortunately', 'unhealthy', 'unique', 'unit', 'unless', 'unlike', 'unpleasant', 'unsweetened', 'update', 'upon', 'ups', 'upset', 'us', 'usa', 'usb', 'use', 'used', 'useful', 'uses', 'using', 'usual', 'usually', 'vacation', 'valley', 'value', 'vanilla', 'varieties', 'variety', 'various', 'vary', 'vegetable', 'vegetables', 'vegetarian', 'veggies', 'vendor', 'versatile', 'version', 'vet', 'via', 'vinegar', 'virtually', 'visit', 'vita', 'vitamin', 'vitamins', 'volume', 'vs', 'waffle', 'waffles', 'wait', 'waiting', 'wake', 'walk', 'walmart', 'walnuts', 'want', 'wanted', 'wanting', 'wants', 'warehouse', 'warm', 'wash', 'waste', 'wasted', 'watch', 'watchers', 'watching', 'water', 'watered', 'watery', 'way', 'ways', 'weak', 'weather', 'web', 'website', 'week', 'weekend', 'weeks', 'weight', 'weird', 'well', 'wellness', 'went', 'wet', 'whatever', 'wheat', 'whenever', 'whether', 'whim', 'whipped', 'white', 'whole', 'wholesome', 'wide', 'wife', 'wild', 'willing', 'windows', 'wine', 'winner', 'winter', 'wise', 'wish', 'within', 'without', 'wonderful', 'wonderfully', 'wondering', 'wonders', 'wont', 'word', 'work', 'worked', 'worker', 'working', 'workout', 'works', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wow', 'wrap', 'wrapped', 'wrappers', 'write', 'writing', 'written', 'wrong', 'wrote', 'xlr', 'yeah', 'year', 'years', 'yeast', 'yellow', 'yes', 'yesterday', 'yet', 'yogurt', 'york', 'young', 'yum', 'yummy', 'zero', 'zip']\n"
     ]
    }
   ],
   "source": [
    "print(count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_value=count_vec.transform(final_time.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4997x2223 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 133123 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bow_value\n",
    "y=final_time.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4997, 2223) (4997,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3347, 2223)\n",
      "(3347,)\n",
      "(1650, 2223)\n",
      "(1650,)\n"
     ]
    }
   ],
   "source": [
    "X_train,x_test,Y_train,y_test=train_test_split(X, y, test_size=0.33, random_state=42,shuffle=False)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_cv, y_train, y_cv = train_test_split(X_train, Y_train,test_size=0.33, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2242, 2223)\n",
      "(2242,)\n",
      "(1105, 2223)\n",
      "(1105,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_cv.shape)\n",
    "print(y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_validator(k,x_train,y_train,x_cv,y_cv):\n",
    "    clf=KNeighborsClassifier(k)\n",
    "    clf.fit(x_train,y_train)\n",
    "    cv_pred=clf.predict(x_cv)\n",
    "    accuracy=accuracy_score(y_cv,cv_pred)*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of k :1 is 81.08597285067873\n",
      "the accuracy of k :3 is 81.26696832579185\n",
      "the accuracy of k :5 is 82.26244343891402\n",
      "the accuracy of k :7 is 82.35294117647058\n",
      "the accuracy of k :9 is 82.62443438914026\n",
      "the accuracy of k :11 is 82.89592760180996\n",
      "the accuracy of k :13 is 82.80542986425338\n",
      "the accuracy of k :15 is 83.07692307692308\n",
      "the accuracy of k :17 is 83.16742081447964\n",
      "the accuracy of k :19 is 83.07692307692308\n",
      "the accuracy of k :21 is 83.16742081447964\n",
      "the accuracy of k :23 is 83.2579185520362\n",
      "the accuracy of k :25 is 83.2579185520362\n",
      "the accuracy of k :27 is 83.16742081447964\n",
      "the accuracy of k :29 is 82.98642533936652\n",
      "the accuracy of k :31 is 82.98642533936652\n",
      "the accuracy of k :33 is 83.16742081447964\n",
      "the accuracy of k :35 is 83.16742081447964\n",
      "the accuracy of k :37 is 82.98642533936652\n",
      "the accuracy of k :39 is 82.98642533936652\n",
      "the accuracy of k :41 is 83.07692307692308\n",
      "the accuracy of k :43 is 83.07692307692308\n",
      "the accuracy of k :45 is 83.07692307692308\n",
      "the accuracy of k :47 is 82.89592760180996\n",
      "the accuracy of k :49 is 82.89592760180996\n",
      "the accuracy of k :51 is 82.89592760180996\n",
      "the accuracy of k :53 is 82.98642533936652\n",
      "the accuracy of k :55 is 82.89592760180996\n",
      "the accuracy of k :57 is 82.89592760180996\n",
      "the accuracy of k :59 is 82.89592760180996\n",
      "the accuracy of k :61 is 82.89592760180996\n",
      "the accuracy of k :63 is 82.89592760180996\n",
      "the accuracy of k :65 is 82.89592760180996\n",
      "the accuracy of k :67 is 82.89592760180996\n",
      "the accuracy of k :69 is 82.89592760180996\n",
      "the accuracy of k :71 is 82.89592760180996\n",
      "the accuracy of k :73 is 82.89592760180996\n",
      "the accuracy of k :75 is 82.89592760180996\n",
      "the accuracy of k :77 is 82.89592760180996\n",
      "the accuracy of k :79 is 82.89592760180996\n",
      "the accuracy of k :81 is 82.89592760180996\n",
      "the accuracy of k :83 is 82.89592760180996\n",
      "the accuracy of k :85 is 82.89592760180996\n",
      "the accuracy of k :87 is 82.89592760180996\n",
      "the accuracy of k :89 is 82.89592760180996\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,90,2):\n",
    "    accuracy=train_cross_validator(i,x_train,y_train,x_cv,y_cv)\n",
    "    print(\"the accuracy of k :{} is {}\".format(i,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##the outcome is just 83% but you can improve it by using snowball stemmer and porter stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sushil/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "    def remove_html(sentence):\n",
    "        html_tag_re_obj = re.compile('<.*>?')\n",
    "        return re.sub(html_tag_re_obj, ' ', sentence)\n",
    "\n",
    "    def remove_punctuations(sentence):\n",
    "        cleaned_sentence = re.sub(r'[^a-zA-Z]', r' ', sentence)\n",
    "        return cleaned_sentence\n",
    "\n",
    "    def decontracted(phrase):\n",
    "        # specific\n",
    "        phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "        # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    #from nltk.corpus import stopwords\n",
    "    import nltk\n",
    "    from tqdm import tqdm\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stopwords = set(stopwords)\n",
    "    stopwords.remove('not')\n",
    "\n",
    "    cleaned_corpus = []\n",
    "    for doc in sentence:\n",
    "        cleaned_doc_1 = remove_html(doc)\n",
    "        cleaned_doc_2 = remove_punctuations(doc)\n",
    "        cleaned_doc_2 = decontracted(cleaned_doc_2)\n",
    "        cleaned_corpus.append(cleaned_doc_2)\n",
    "    count = 0\n",
    "\n",
    "    filtered_corpus = list(map(lambda doc: ' '.join(list(filter(lambda word: True if word not in stopwords else False\\\n",
    "                                                                , doc.split()))),cleaned_corpus))\n",
    "    process_text = list(map(lambda doc: ' '.join(list(map(stemmer.stem, doc.split()))),filtered_corpus))\n",
    "\n",
    "    return process_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=preprocess_text(final_data.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4997,)\n",
      "4997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['thirti buck', 'fli begon', 'wow make islick', 'great product', 'good stuff']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(final_data.Summary.shape)\n",
    "print(len(clean_text))\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n",
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4,5]\n",
    "ab=list(filter(lambda x: x%2==0,a))\n",
    "print(ab)\n",
    "a=[1,2,3,4,5]\n",
    "ab=list(map(lambda x: x**2,a))\n",
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\"this is sushil chahuan testing\",\"thie is power ranger\"]\n",
    "filtered_corpus = list(map(lambda doc: ' '.join(list(filter(lambda word: True if word not in stopwords else False\\\n",
    "                                                                , doc.split()))),text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sushil chahuan testing', 'thie power ranger']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sushil chahuan test', 'thie power ranger']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text = list(map(lambda doc: ' '.join(list(map(stemmer.stem, doc.split()))),filtered_corpus))\n",
    "process_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>2774</td>\n",
       "      <td>B00002NCJC</td>\n",
       "      <td>A196AJHU9EASJN</td>\n",
       "      <td>Alex Chaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>1282953600</td>\n",
       "      <td>thirty bucks</td>\n",
       "      <td>product available victor traps unreal course t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>2775</td>\n",
       "      <td>B00002NCJC</td>\n",
       "      <td>A13RRPGE79XFFH</td>\n",
       "      <td>reader48</td>\n",
       "      <td>1</td>\n",
       "      <td>1281052800</td>\n",
       "      <td>flies begone</td>\n",
       "      <td>used victor fly bait seasons ca not beat great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1244</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A3B8RCEI0FXFI6</td>\n",
       "      <td>B G Chase</td>\n",
       "      <td>1</td>\n",
       "      <td>962236800</td>\n",
       "      <td>wow make islickers</td>\n",
       "      <td>received shipment could hardly wait try produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1245</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A29Z5PI9BW2PU3</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>1</td>\n",
       "      <td>961718400</td>\n",
       "      <td>great product</td>\n",
       "      <td>really good idea final product outstanding use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>3204</td>\n",
       "      <td>B000084DVR</td>\n",
       "      <td>A1UGDJP1ZJWVPF</td>\n",
       "      <td>T. Moore \"thoughtful reader\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1177977600</td>\n",
       "      <td>good stuff</td>\n",
       "      <td>glad cocker standard poodle puppy loves stuff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>765</td>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>A1OEL4UZT3KKI4</td>\n",
       "      <td>coffee drinker in PA \"coffee drinker in PA\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1344988800</td>\n",
       "      <td>great coffee terrible price</td>\n",
       "      <td>one best choices opinion also adore amazon nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>764</td>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>ADDBLG0CFY9AI</td>\n",
       "      <td>S.A.D.</td>\n",
       "      <td>1</td>\n",
       "      <td>1326758400</td>\n",
       "      <td>best tassimo</td>\n",
       "      <td>tried many tassimo flavors far favorite normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>763</td>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>A3N9477PUE6WMR</td>\n",
       "      <td>patc477</td>\n",
       "      <td>1</td>\n",
       "      <td>1323302400</td>\n",
       "      <td>good tasting cup joe</td>\n",
       "      <td>bold blend great taste flavor comes bursting u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>768</td>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>A2CAZG1CQ8BQI5</td>\n",
       "      <td>Patricia J. Nohalty</td>\n",
       "      <td>1</td>\n",
       "      <td>1337212800</td>\n",
       "      <td>kona tassimo</td>\n",
       "      <td>coffee available tassimo kona richest flavor f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1478</td>\n",
       "      <td>B009UOFU20</td>\n",
       "      <td>AJVB004EB0MVK</td>\n",
       "      <td>D. Christofferson</td>\n",
       "      <td>0</td>\n",
       "      <td>1345852800</td>\n",
       "      <td>weak coffee not good premium product price</td>\n",
       "      <td>coffee supposedly premium tastes watery thin n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4997 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  \\\n",
       "2546  2774  B00002NCJC  A196AJHU9EASJN   \n",
       "2547  2775  B00002NCJC  A13RRPGE79XFFH   \n",
       "1145  1244  B00002Z754  A3B8RCEI0FXFI6   \n",
       "1146  1245  B00002Z754  A29Z5PI9BW2PU3   \n",
       "2942  3204  B000084DVR  A1UGDJP1ZJWVPF   \n",
       "...    ...         ...             ...   \n",
       "711    765  B009HINRX8  A1OEL4UZT3KKI4   \n",
       "710    764  B009HINRX8   ADDBLG0CFY9AI   \n",
       "709    763  B009HINRX8  A3N9477PUE6WMR   \n",
       "713    768  B009HINRX8  A2CAZG1CQ8BQI5   \n",
       "1362  1478  B009UOFU20   AJVB004EB0MVK   \n",
       "\n",
       "                                      ProfileName  Score        Time  \\\n",
       "2546                                 Alex Chaffee      1  1282953600   \n",
       "2547                                     reader48      1  1281052800   \n",
       "1145                                    B G Chase      1   962236800   \n",
       "1146                                       Robbie      1   961718400   \n",
       "2942                 T. Moore \"thoughtful reader\"      1  1177977600   \n",
       "...                                           ...    ...         ...   \n",
       "711   coffee drinker in PA \"coffee drinker in PA\"      1  1344988800   \n",
       "710                                        S.A.D.      1  1326758400   \n",
       "709                                       patc477      1  1323302400   \n",
       "713                           Patricia J. Nohalty      1  1337212800   \n",
       "1362                            D. Christofferson      0  1345852800   \n",
       "\n",
       "                                         Summary  \\\n",
       "2546                                thirty bucks   \n",
       "2547                                flies begone   \n",
       "1145                          wow make islickers   \n",
       "1146                               great product   \n",
       "2942                                  good stuff   \n",
       "...                                          ...   \n",
       "711                  great coffee terrible price   \n",
       "710                                 best tassimo   \n",
       "709                         good tasting cup joe   \n",
       "713                                 kona tassimo   \n",
       "1362  weak coffee not good premium product price   \n",
       "\n",
       "                                                   Text  \n",
       "2546  product available victor traps unreal course t...  \n",
       "2547  used victor fly bait seasons ca not beat great...  \n",
       "1145  received shipment could hardly wait try produc...  \n",
       "1146  really good idea final product outstanding use...  \n",
       "2942  glad cocker standard poodle puppy loves stuff ...  \n",
       "...                                                 ...  \n",
       "711   one best choices opinion also adore amazon nee...  \n",
       "710   tried many tassimo flavors far favorite normal...  \n",
       "709   bold blend great taste flavor comes bursting u...  \n",
       "713   coffee available tassimo kona richest flavor f...  \n",
       "1362  coffee supposedly premium tastes watery thin n...  \n",
       "\n",
       "[4997 rows x 8 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
